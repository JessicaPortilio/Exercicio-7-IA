{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "IA - Exercício - 06 - Rede Neural Artificial - Python - SkLearn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tVff4dgKyg"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xB4G8ogKym"
      },
      "source": [
        "### Carregando Arquivo de Treinamento (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5MRh5ZfgKyn",
        "outputId": "09d8e145-c50e-4cbd-caa4-7ae5a25c1d48"
      },
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "#'https://raw.githubusercontent.com/JessicaPortilio/Exercicio-7-IA/main/diabetes.csv'\n",
        "url = 'https://raw.githubusercontent.com/JessicaPortilio/Exercicio-7-IA/main/diabetes.csv'\n",
        "base_Treinamento = pd.read_csv(url,sep=',', encoding = 'latin1').values\n",
        "print(\"---------------------------------\")\n",
        "print(\"Dados dos Pacientes - TREINAMENTO\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento[:, 0:8])\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(\"Classificação Supervisionada\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Treinamento[:, 8])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Dados dos Pacientes - TREINAMENTO\n",
            "---------------------------------\n",
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "----------------------------\n",
            "Classificação Supervisionada\n",
            "----------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPpDXy7cgKyp"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4nvyQJegKyq",
        "outputId": "3664afef-167b-4b3d-e98e-5234021f4e82"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "#lb.fit([1,27])\n",
        "#Pregnancies = lb.transform(base_Treinamento[:,0])  \n",
        "\n",
        "#Glucose = lb.transform(base_Treinamento[:,1])\n",
        "\n",
        "#BloodPressure = lb.transform(base_Treinamento[:,2])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "#lb.fit(['grandes', 'pequenas'])\n",
        "#SkinThickness = lb.transform(base_Treinamento[:,3])\n",
        "#Insulin = lb.transform(base_Treinamento[:,4])\n",
        "\n",
        "\n",
        "#lb.fit([1,75])\n",
        "#Age = lb.transform(base_Treinamento[:,7])\n",
        "#Atributos categóricos com valores saudável e doente\n",
        "#lb.fit([0, 1])\n",
        "#Outcome = lb.transform(base_Treinamento[:,8])\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((base_Treinamento[:,0],base_Treinamento[:,1],base_Treinamento[:,2],base_Treinamento[:,3],base_Treinamento[:,4],base_Treinamento[:,5],base_Treinamento[:,6],base_Treinamento[:,7]))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"Classificação Supervisionada - Numéricos\")\n",
        "print(\"----------------------------------------\")\n",
        "diagnostico_norm = np.hstack(base_Treinamento[:,8])\n",
        "print(diagnostico_norm)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "----------------------------------------\n",
            "Classificação Supervisionada - Numéricos\n",
            "----------------------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4FUfD5gKyr"
      },
      "source": [
        "### Treinamento do Neurônio Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDmPLB5FgKys",
        "outputId": "e3374962-ebe8-466b-f9ad-c673af7d499a"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "# Treinamento do Perceptron a partir dos atributos de entrada e classificações\n",
        "modelo = Perceptron()\n",
        "modelo.fit(atributos_norm, diagnostico_norm)\n",
        "\n",
        "# Acurácia do modelo, que é : 1 - (predições erradas / total de predições)\n",
        "# Acurácia do modelo: indica uma performance geral do modelo. \n",
        "# Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
        "# (VP+VN)/N\n",
        "print('Acurácia: %.3f' % modelo.score(atributos_norm, diagnostico_norm))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwrAoNwgKyt"
      },
      "source": [
        "### ----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKPw4jagKyu"
      },
      "source": [
        "# Validação do Aprendizado "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUmMoPHgKyv"
      },
      "source": [
        "### Predição Simples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4MRpx9PgKyw",
        "outputId": "0049840a-f2c9-4a7f-fb86-bdfefa951681"
      },
      "source": [
        "#Luiz = [[0,0,1,1]]\n",
        "print( modelo.predict([[8,85,55,0,16,39.6,0.93,27]]))\n",
        "#Laura = [[1,1,0,1]]\n",
        "print( modelo.predict([[11,138,74,26,144,36.1,0.557,34]]))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.]\n",
            "[1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VweXD-8_gKyx"
      },
      "source": [
        "### Predição a partir de base de dados (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceg0-DfVgKyx",
        "outputId": "2138ffa4-bacf-4009-d54a-1d2b43d5e761"
      },
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/JessicaPortilio/Exercicio-7-IA/main/teste.csv'\n",
        "base_Testes = pd.read_csv(url,sep=',', encoding = 'latin1').values\n",
        "print(\"----------------------------\")\n",
        "print(\"Dados dos Pacientes - TESTES\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Testes)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Testes[:, 0:8])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "Dados dos Pacientes - TESTES\n",
            "----------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01]\n",
            " [8.000e+00 8.500e+01 5.500e+01 0.000e+00 1.600e+01 3.960e+01 9.300e-01\n",
            "  2.700e+01]\n",
            " [1.100e+01 1.380e+02 7.400e+01 2.600e+01 1.440e+02 3.610e+01 5.570e-01\n",
            "  3.400e+01]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01]\n",
            " [8.000e+00 8.500e+01 5.500e+01 0.000e+00 1.600e+01 3.960e+01 9.300e-01\n",
            "  2.700e+01]\n",
            " [1.100e+01 1.380e+02 7.400e+01 2.600e+01 1.440e+02 3.610e+01 5.570e-01\n",
            "  3.400e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6JQnLaEgKyx"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJM8C3IDgKyy",
        "outputId": "f054904f-dbc1-4c62-ba30-47be39e587cd"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "#lb.fit(['sim', 'não'])\n",
        "#febre = lb.transform(base_Testes[:,1])  \n",
        "#enjoo = lb.transform(base_Testes[:,2])\n",
        "#dores = lb.transform(base_Testes[:,4])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "#lb.fit(['grandes', 'pequenas'])\n",
        "#manchas = lb.transform(base_Testes[:,7])\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((base_Testes[:,0],base_Testes[:,1],base_Testes[:,2],base_Testes[:,3],base_Testes[:,4],base_Testes[:,5],base_Testes[:,6],base_Testes[:,7]))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01]\n",
            " [8.000e+00 8.500e+01 5.500e+01 0.000e+00 1.600e+01 3.960e+01 9.300e-01\n",
            "  2.700e+01]\n",
            " [1.100e+01 1.380e+02 7.400e+01 2.600e+01 1.440e+02 3.610e+01 5.570e-01\n",
            "  3.400e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QO3B6S3gKyy"
      },
      "source": [
        "### Predição da Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZovGGdmgKyz",
        "outputId": "856e6e8e-70c6-46a9-9099-803bb526f636"
      },
      "source": [
        "base_Predicao = modelo.predict((atributos_norm))\n",
        "print(\"Classificações: \", base_Predicao)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificações:  [1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ZxJwGAgKyz"
      },
      "source": [
        "### Retorno aos valores Categóricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE96lEuPgKy0",
        "outputId": "48f12717-c399-423f-f13e-939d83e39e8c"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "#lb.fit(['sim', 'não'])\n",
        "#febre = lb.inverse_transform(atributos_norm[:,0])  \n",
        "#enjoo = lb.inverse_transform(atributos_norm[:,1])\n",
        "#dores = lb.inverse_transform(atributos_norm[:,3])\n",
        "\n",
        "#Atributos categóricos com valores pequenas e grandes\n",
        "#lb.fit(['grandes', 'pequenas'])\n",
        "#manchas = lb.inverse_transform(atributos_norm[:,2])\n",
        "\n",
        "#Atributos categóricos com valores saudável e doente\n",
        "#lb.fit([0, 1])\n",
        "#predicao = lb.inverse_transform(base_Predicao)\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_cat = np.column_stack((base_Testes[:,0],base_Testes[:,1],base_Testes[:,2],base_Testes[:,3],base_Testes[:,4],base_Testes[:,5],base_Predicao))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_cat)\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[  6.  148.   72.   35.    0.   33.6   1. ]\n",
            " [  1.   85.   66.   29.    0.   26.6   1. ]\n",
            " [  8.  183.   64.    0.    0.   23.3   1. ]\n",
            " [  1.   89.   66.   23.   94.   28.1   0. ]\n",
            " [  0.  137.   40.   35.  168.   43.1   1. ]\n",
            " [  5.  116.   74.    0.    0.   25.6   1. ]\n",
            " [  3.   78.   50.   32.   88.   31.    1. ]\n",
            " [ 10.  115.    0.    0.    0.   35.3   1. ]\n",
            " [  2.  197.   70.   45.  543.   30.5   0. ]\n",
            " [  8.  125.   96.    0.    0.    0.    1. ]\n",
            " [  8.   85.   55.    0.   16.   39.6   1. ]\n",
            " [ 11.  138.   74.   26.  144.   36.1   1. ]]\n"
          ]
        }
      ]
    }
  ]
}